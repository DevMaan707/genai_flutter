#include "genai_bridge.h"
#include "ggml/src/ggml.h"
#include "embedding_model.h"
#include "vector_db.h"
#include <android/log.h>
#include <string>
#include <vector>
#include <algorithm>
#include <cmath>
#include <map>

#define LOG_TAG "GenaiNative"
#define LOGI(...) __android_log_print(ANDROID_LOG_INFO, LOG_TAG, __VA_ARGS__)
#define LOGE(...) __android_log_print(ANDROID_LOG_ERROR, LOG_TAG, __VA_ARGS__)

// Global initialization flag and database manager
static bool g_initialized = false;
static std::map<std::string, std::shared_ptr<VectorDB>> g_databases;
static std::mutex g_db_mutex;

// LlmContext implementation
LlmContext::LlmContext(const std::string& model_path) {
    LOGI("Loading model from %s", model_path.c_str());

    // Initialize GGML params for model loading
    struct ggml_init_params params = {
        .mem_size   = 512 * 1024 * 1024,
        .mem_buffer = NULL,
    };

    ctx = ggml_init(params);
    if (!ctx) {
        throw std::runtime_error("Failed to initialize GGML context");
    }

    // Load the model
    // Note: This is a simplified example - actual model loading would depend on your model format
    model = nullptr;  // Replace with actual model loading

    LOGI("Model loaded successfully");
}

LlmContext::~LlmContext() {
    if (ctx) {
        if (model) {
            // Free model resources
            // Note: In a real implementation, you'd have proper model cleanup
        }
        ggml_free(ctx);
        ctx = nullptr;
        model = nullptr;
    }

    LOGI("Model resources released");
}

std::string LlmContext::generate(const std::string& prompt, int max_tokens, double temperature) {
    std::lock_guard<std::mutex> lock(mtx);

    LOGI("Generating with prompt: %s", prompt.c_str());

    // This is a simplified implementation for the example
    // In a real implementation, you'd:
    // 1. Tokenize the prompt
    // 2. Run the model inference
    // 3. Sample from the output distribution
    // 4. Decode tokens to text

    // Simplified implementation that returns a placeholder response
    return "This is a placeholder response. In a real implementation, this would be generated by the language model based on the prompt: " + prompt;
}

// JNI implementation
extern "C" {

JNIEXPORT void JNICALL Java_com_genai_flutter_GenaiFlutterPlugin_nativeInitialize(
    JNIEnv* env, jobject thiz) {

    if (g_initialized) {
        return;
    }

    LOGI("Initializing native components");

    // Initialize GGML
    struct ggml_init_params params = {
        .mem_size   = 16 * 1024 * 1024,
        .mem_buffer = NULL,
    };
    struct ggml_context* ctx = ggml_init(params);
    if (ctx) {
        ggml_free(ctx); // Just testing initialization
        g_initialized = true;
        LOGI("GGML initialized successfully");
    } else {
        LOGE("Failed to initialize GGML");
    }
}

JNIEXPORT jlong JNICALL Java_com_genai_flutter_GenaiFlutterPlugin_nativeLoadModel(
    JNIEnv* env, jobject thiz, jstring model_path) {

    if (!g_initialized) {
        LOGE("Library not initialized. Call nativeInitialize first.");
        return 0;
    }

    const char* path = env->GetStringUTFChars(model_path, nullptr);
    LlmContext* ctx = nullptr;

    try {
        ctx = new LlmContext(path);
    } catch (const std::exception& e) {
        LOGE("Exception in nativeLoadModel: %s", e.what());
    }

    env->ReleaseStringUTFChars(model_path, path);
    return reinterpret_cast<jlong>(ctx);
}

JNIEXPORT jlong JNICALL Java_com_genai_flutter_GenaiFlutterPlugin_nativeLoadEmbeddingModel(
    JNIEnv* env, jobject thiz, jstring model_path) {

    if (!g_initialized) {
        LOGE("Library not initialized. Call nativeInitialize first.");
        return 0;
    }

    const char* path = env->GetStringUTFChars(model_path, nullptr);
    EmbeddingModel* model = nullptr;

    try {
        model = new EmbeddingModel(path);
    } catch (const std::exception& e) {
        LOGE("Exception in nativeLoadEmbeddingModel: %s", e.what());
    }

    env->ReleaseStringUTFChars(model_path, path);
    return reinterpret_cast<jlong>(model);
}

JNIEXPORT jstring JNICALL Java_com_genai_flutter_GenaiFlutterPlugin_nativeGenerate(
    JNIEnv* env, jobject thiz, jlong context_ptr, jstring prompt, jint max_tokens, jdouble temperature) {

    auto* ctx = reinterpret_cast<LlmContext*>(context_ptr);
    if (!ctx) {
        LOGE("Invalid context pointer");
        return env->NewStringUTF("Error: Invalid model context");
    }

    const char* prompt_str = env->GetStringUTFChars(prompt, nullptr);
    std::string result;

    try {
        result = ctx->generate(prompt_str, max_tokens, temperature);
    } catch (const std::exception& e) {
        LOGE("Exception in nativeGenerate: %s", e.what());
        result = std::string("Error: ") + e.what();
    }

    env->ReleaseStringUTFChars(prompt, prompt_str);
    return env->NewStringUTF(result.c_str());
}

JNIEXPORT jboolean JNICALL Java_com_genai_flutter_GenaiFlutterPlugin_nativeCreateVectorDatabase(
    JNIEnv* env, jobject thiz, jstring db_name, jint embedding_dimension) {

    const char* name = env->GetStringUTFChars(db_name, nullptr);
    bool success = false;

    try {
        std::string db_name_str(name);

        {
            std::lock_guard<std::mutex> lock(g_db_mutex);

            // Check if database already exists
            if (g_databases.find(db_name_str) != g_databases.end()) {
                // Database already exists
                success = true;
            } else {
                // Create new database
                auto db = std::make_shared<VectorDB>(db_name_str, embedding_dimension);
                if (db->isInitialized()) {
                    g_databases[db_name_str] = db;
                    success = true;
                }
            }
        }
    } catch (const std::exception& e) {
        LOGE("Exception in nativeCreateVectorDatabase: %s", e.what());
    }

    env->ReleaseStringUTFChars(db_name, name);
    return success ? JNI_TRUE : JNI_FALSE;
}

JNIEXPORT jboolean JNICALL Java_com_genai_flutter_GenaiFlutterPlugin_nativeAddToKnowledgeBase(
    JNIEnv* env, jobject thiz, jlong emb_model_ptr, jstring content, jstring document_id, jstring db_name) {

    auto* embModel = reinterpret_cast<EmbeddingModel*>(emb_model_ptr);
    if (!embModel) {
        LOGE("Invalid embedding model pointer");
        return JNI_FALSE;
    }

    const char* content_str = env->GetStringUTFChars(content, nullptr);
    const char* doc_id_str = env->GetStringUTFChars(document_id, nullptr);
    const char* db_name_str = env->GetStringUTFChars(db_name, nullptr);

    bool success = false;

    try {
        std::string db_name_cpp(db_name_str);
        std::shared_ptr<VectorDB> db;

        {
            std::lock_guard<std::mutex> lock(g_db_mutex);

            // Check if database exists
            auto it = g_databases.find(db_name_cpp);
            if (it == g_databases.end()) {
                // Create database if it doesn't exist
                db = std::make_shared<VectorDB>(db_name_cpp, embModel->embeddingDimension());
                if (db->isInitialized()) {
                    g_databases[db_name_cpp] = db;
                } else {
                    throw std::runtime_error("Failed to initialize vector database");
                }
            } else {
                db = it->second;
            }
        }

        // Generate embedding for the document
        std::vector<float> embedding = embModel->generateEmbedding(content_str);

        // Add to vector database
        success = db->addDocument(doc_id_str, content_str, embedding);
    } catch (const std::exception& e) {
        LOGE("Exception in nativeAddToKnowledgeBase: %s", e.what());
    }

    env->ReleaseStringUTFChars(content, content_str);
    env->ReleaseStringUTFChars(document_id, doc_id_str);
    env->ReleaseStringUTFChars(db_name, db_name_str);

    return success ? JNI_TRUE : JNI_FALSE;
}

JNIEXPORT jstring JNICALL Java_com_genai_flutter_GenaiFlutterPlugin_nativeGenerateWithContext(
    JNIEnv* env, jobject thiz, jlong llm_ptr, jlong emb_model_ptr, jstring query,
    jstring db_name, jint max_tokens, jdouble temperature, jint top_k) {

    auto* llm = reinterpret_cast<LlmContext*>(llm_ptr);
    auto* embModel = reinterpret_cast<EmbeddingModel*>(emb_model_ptr);

    if (!llm) {
        LOGE("Invalid LLM context pointer");
        return env->NewStringUTF("Error: Invalid language model context");
    }

    if (!embModel) {
        LOGE("Invalid embedding model pointer");
        return env->NewStringUTF("Error: Invalid embedding model context");
    }

    const char* query_str = env->GetStringUTFChars(query, nullptr);
    const char* db_name_str = env->GetStringUTFChars(db_name, nullptr);

    std::string result;

    try {
        std::string db_name_cpp(db_name_str);
        std::shared_ptr<VectorDB> db;

        {
            std::lock_guard<std::mutex> lock(g_db_mutex);

            // Check if database exists
            auto it = g_databases.find(db_name_cpp);
            if (it == g_databases.end()) {
                // If database doesn't exist, just use the query directly
                result = llm->generate(query_str, max_tokens, temperature);
                env->ReleaseStringUTFChars(query, query_str);
                env->ReleaseStringUTFChars(db_name, db_name_str);
                return env->NewStringUTF(result.c_str());
            }

            db = it->second;
        }

        // Generate embedding for the query
        std::vector<float> queryEmbedding = embModel->generateEmbedding(query_str);

        // Search for similar documents
        std::vector<DocumentMatch> matches = db->findSimilarDocuments(queryEmbedding, top_k);

        if (matches.empty()) {
            // No context found, just use the query directly
            result = llm->generate(query_str, max_tokens, temperature);
        } else {
            // Create a prompt with context
            std::string contextualPrompt = "Using the following information:\n\n";

            for (const auto& match : matches) {
                contextualPrompt += "---\n" + match.content + "\n---\n\n";
            }

            contextualPrompt += "Answer the question: " + std::string(query_str);

            // Generate response with the contextual prompt
            result = llm->generate(contextualPrompt, max_tokens, temperature);
        }
    } catch (const std::exception& e) {
        LOGE("Exception in nativeGenerateWithContext: %s", e.what());
        result = std::string("Error: ") + e.what();
    }

    env->ReleaseStringUTFChars(query, query_str);
    env->ReleaseStringUTFChars(db_name, db_name_str);

    return env->NewStringUTF(result.c_str());
}

JNIEXPORT jobject JNICALL Java_com_genai_flutter_GenaiFlutterPlugin_nativeSearchSimilarDocuments(
    JNIEnv* env, jobject thiz, jlong emb_model_ptr, jstring query, jstring db_name, jint top_k) {

    auto* embModel = reinterpret_cast<EmbeddingModel*>(emb_model_ptr);
    if (!embModel) {
        LOGE("Invalid embedding model pointer");
        return nullptr;
    }

    const char* query_str = env->GetStringUTFChars(query, nullptr);
    const char* db_name_str = env->GetStringUTFChars(db_name, nullptr);

    // Create ArrayList to return
    jclass arrayListClass = env->FindClass("java/util/ArrayList");
    jmethodID arrayListConstructor = env->GetMethodID(arrayListClass, "<init>", "()V");
    jobject resultList = env->NewObject(arrayListClass, arrayListConstructor);
    jmethodID addMethod = env->GetMethodID(arrayListClass, "add", "(Ljava/lang/Object;)Z");

    try {
        std::string db_name_cpp(db_name_str);
        std::shared_ptr<VectorDB> db;

        {
            std::lock_guard<std::mutex> lock(g_db_mutex);

            // Check if database exists
            auto it = g_databases.find(db_name_cpp);
            if (it == g_databases.end()) {
                // No database, return empty list
                env->ReleaseStringUTFChars(query, query_str);
                env->ReleaseStringUTFChars(db_name, db_name_str);
                return resultList;
            }

            db = it->second;
        }

        // Generate embedding for the query
        std::vector<float> queryEmbedding = embModel->generateEmbedding(query_str);

        // Search for similar documents
        std::vector<DocumentMatch> matches = db->findSimilarDocuments(queryEmbedding, top_k);

        // Create HashMap class and method references
        jclass hashMapClass = env->FindClass("java/util/HashMap");
        jmethodID hashMapConstructor = env->GetMethodID(hashMapClass, "<init>", "()V");
        jmethodID putMethod = env->GetMethodID(hashMapClass, "put",
            "(Ljava/lang/Object;Ljava/lang/Object;)Ljava/lang/Object;");

        // Add matches to the ArrayList
        for (const auto& match : matches) {
            // Create HashMap for each match
            jobject matchMap = env->NewObject(hashMapClass, hashMapConstructor);

            // Add document ID
            jstring jDocId = env->NewStringUTF(match.id.c_str());
            env->CallObjectMethod(matchMap, putMethod,
                env->NewStringUTF("id"), jDocId);

            // Add content
            jstring jContent = env->NewStringUTF(match.content.c_str());
            env->CallObjectMethod(matchMap, putMethod,
                env->NewStringUTF("content"), jContent);

            // Add similarity score
            jclass doubleClass = env->FindClass("java/lang/Double");
            jmethodID doubleConstructor = env->GetMethodID(doubleClass, "<init>", "(D)V");
            jobject jScore = env->NewObject(doubleClass, doubleConstructor, match.score);
            env->CallObjectMethod(matchMap, putMethod,
                env->NewStringUTF("score"), jScore);

            // Add to result list
            env->CallBooleanMethod(resultList, addMethod, matchMap);

            // Clean up local references
            env->DeleteLocalRef(jDocId);
            env->DeleteLocalRef(jContent);
            env->DeleteLocalRef(jScore);
            env->DeleteLocalRef(matchMap);
        }
    } catch (const std::exception& e) {
        LOGE("Exception in nativeSearchSimilarDocuments: %s", e.what());
    }

    env->ReleaseStringUTFChars(query, query_str);
    env->ReleaseStringUTFChars(db_name, db_name_str);

    return resultList;
}

JNIEXPORT void JNICALL Java_com_genai_flutter_GenaiFlutterPlugin_nativeUnloadModel(
    JNIEnv* env, jobject thiz, jlong context_ptr) {

    auto* ctx = reinterpret_cast<LlmContext*>(context_ptr);
    if (ctx) {
        delete ctx;
    }
}

JNIEXPORT void JNICALL Java_com_genai_flutter_GenaiFlutterPlugin_nativeUnloadEmbeddingModel(
    JNIEnv* env, jobject thiz, jlong emb_model_ptr) {

    auto* model = reinterpret_cast<EmbeddingModel*>(emb_model_ptr);
    if (model) {
        delete model;
    }
}

JNIEXPORT void JNICALL Java_com_genai_flutter_GenaiFlutterPlugin_nativeDispose(
    JNIEnv* env, jobject thiz) {

    if (g_initialized) {
        LOGI("Cleaning up global resources");

        // Clear databases
        {
            std::lock_guard<std::mutex> lock(g_db_mutex);
            g_databases.clear();
        }

        g_initialized = false;
    }
}

} // extern "C"
